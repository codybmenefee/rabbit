# =============================================================================
# LLM-Enhanced YouTube Scraping Configuration via OpenRouter
# =============================================================================
# Copy this file to .env and configure the LLM scraping service
# This enables AI-powered data extraction through OpenRouter's unified API

# =============================================================================
# LLM Service Configuration
# =============================================================================

# Enable LLM scraping service
LLM_SCRAPING_ENABLED=true

# LLM Provider: 'anthropic', 'openai', 'meta', 'google', 'mistral'
# Note: These map to OpenRouter's model names automatically
LLM_PROVIDER=google

# =============================================================================
# OpenRouter Configuration
# =============================================================================

# OpenRouter API Key (get from https://openrouter.ai/keys)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Optional: Your site URL for OpenRouter's referrer tracking
OPENROUTER_REFERER=https://your-site.com

# Optional: Your app name for OpenRouter's request tracking
OPENROUTER_TITLE=Your App Name

# =============================================================================
# Model Configuration
# =============================================================================

# Model selection (automatically mapped to OpenRouter format)
# Google: gemma-3-4b-it (recommended), gemma-3n-e4b-it, gemini-pro, gemini-pro-vision
# Anthropic: claude-3-haiku-20240307, claude-3-sonnet-20240229, claude-3-opus-20240229
# OpenAI: gpt-3.5-turbo, gpt-4-turbo-preview, gpt-4o
# Meta: llama-3.1-8b-instruct, llama-3.1-70b-instruct
# Mistral: mistral-7b-instruct, mixtral-8x7b-instruct
LLM_MODEL=gemma-3-4b-it

# Token limit per request (1000-4000 recommended)
LLM_MAX_TOKENS=2000

# Temperature for response randomness (0.0-1.0, 0.1 recommended for extraction)
LLM_TEMPERATURE=0.1

# =============================================================================
# Performance Configuration
# =============================================================================

# Maximum concurrent API requests
LLM_MAX_CONCURRENT_REQUESTS=5

# Delay between requests (ms) - respects rate limits
LLM_REQUEST_DELAY_MS=1000

# Batch size for processing multiple videos
LLM_BATCH_SIZE=10

# =============================================================================
# Cost Management
# =============================================================================

# Maximum cost per session ($USD) - processing stops when reached
LLM_COST_LIMIT=10.0

# =============================================================================
# Caching Configuration
# =============================================================================

# Enable result caching (recommended)
LLM_CACHE_ENABLED=true

# Cache TTL in seconds (2 hours = 7200)
LLM_CACHE_TTL=7200

# =============================================================================
# Advanced Configuration
# =============================================================================

# HTML chunk size for processing (characters)
LLM_HTML_CHUNK_SIZE=50000

# Enable fallback to traditional scraping on LLM failure
LLM_ENABLE_FALLBACK=true

# Retry attempts for failed requests
LLM_RETRY_ATTEMPTS=3

# Request timeout (milliseconds)
LLM_TIMEOUT=30000

# =============================================================================
# OpenRouter Model Pricing (as of 2024, subject to change)
# =============================================================================
# Anthropic Claude 3 Haiku: $0.25/$1.25 per 1M tokens (input/output)
# Anthropic Claude 3 Sonnet: $3/$15 per 1M tokens
# OpenAI GPT-3.5 Turbo: $1.5/$2 per 1M tokens
# OpenAI GPT-4 Turbo: $10/$30 per 1M tokens
# Meta Llama 3.1 8B: $0.2/$0.2 per 1M tokens
# Meta Llama 3.1 70B: $0.9/$0.9 per 1M tokens
#
# Estimated cost per video: $0.002-0.008 (depending on model and content)
# For 18,154 videos: $36-145 total estimated cost